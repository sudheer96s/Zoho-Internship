{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fsEGyDUR2jXJ"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rSJVLk0L2ko5"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_val_data = datasets.FashionMNIST(root='/home/manchik-pt7714/Documents/ML Tasks/data/temp/',train=True,transform=transform,download=False)\n",
    "test_data = datasets.FashionMNIST(root='/home/manchik-pt7714/Documents/ML Tasks/data/temp/',train=False,transform=transform,download=False)\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(train_val_data))\n",
    "val_size = len(train_val_data) - train_size\n",
    "train_data, val_data = torch.utils.data.random_split(train_val_data, [train_size, val_size])\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_load = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_load = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_load = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "P24M2Nqi3Igi"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "      super(CNN, self).__init__()\n",
    "      self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "      self.pool = nn.MaxPool2d(2, 2)\n",
    "      self.fc1 = nn.Linear(32 * 13 * 13, 150)\n",
    "      self.fc2 = nn.Linear(150, 10)\n",
    "      self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "  def forward(self, x):\n",
    "      x = self.pool(torch.relu(self.conv1(x)))\n",
    "      x = x.view(-1, 32 * 13 * 13)\n",
    "      x = torch.relu(self.fc1(x))\n",
    "      x = self.dropout(x)\n",
    "      x = self.fc2(x)\n",
    "      return x\n",
    "\n",
    "model = CNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QngeSGWh3OBN"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mt3kAZrZ25sd",
    "outputId": "b38020d3-3134-46af-90ea-dff9b14280cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Training Loss: 0.8361, Validation Loss: 0.5129\n",
      "Epoch: 2/100, Training Loss: 0.5101, Validation Loss: 0.4235\n",
      "Epoch: 3/100, Training Loss: 0.4419, Validation Loss: 0.3867\n",
      "Epoch: 4/100, Training Loss: 0.4039, Validation Loss: 0.3656\n",
      "Epoch: 5/100, Training Loss: 0.3761, Validation Loss: 0.3454\n",
      "Epoch: 6/100, Training Loss: 0.3539, Validation Loss: 0.3343\n",
      "Epoch: 7/100, Training Loss: 0.3400, Validation Loss: 0.3223\n",
      "Epoch: 8/100, Training Loss: 0.3252, Validation Loss: 0.3165\n",
      "Epoch: 9/100, Training Loss: 0.3170, Validation Loss: 0.3048\n",
      "Epoch: 10/100, Training Loss: 0.3062, Validation Loss: 0.3036\n",
      "Epoch: 11/100, Training Loss: 0.2968, Validation Loss: 0.2944\n",
      "Epoch: 12/100, Training Loss: 0.2891, Validation Loss: 0.2927\n",
      "Epoch: 13/100, Training Loss: 0.2834, Validation Loss: 0.2890\n",
      "Epoch: 14/100, Training Loss: 0.2788, Validation Loss: 0.2813\n",
      "Epoch: 15/100, Training Loss: 0.2716, Validation Loss: 0.2782\n",
      "Epoch: 16/100, Training Loss: 0.2639, Validation Loss: 0.2740\n",
      "Epoch: 17/100, Training Loss: 0.2600, Validation Loss: 0.2724\n",
      "Epoch: 18/100, Training Loss: 0.2528, Validation Loss: 0.2694\n",
      "Epoch: 19/100, Training Loss: 0.2490, Validation Loss: 0.2669\n",
      "Epoch: 20/100, Training Loss: 0.2465, Validation Loss: 0.2664\n",
      "Epoch: 21/100, Training Loss: 0.2386, Validation Loss: 0.2670\n",
      "Epoch: 22/100, Training Loss: 0.2367, Validation Loss: 0.2655\n",
      "Epoch: 23/100, Training Loss: 0.2307, Validation Loss: 0.2630\n",
      "Epoch: 24/100, Training Loss: 0.2278, Validation Loss: 0.2582\n",
      "Epoch: 25/100, Training Loss: 0.2255, Validation Loss: 0.2608\n",
      "Epoch: 26/100, Training Loss: 0.2197, Validation Loss: 0.2590\n",
      "Epoch: 27/100, Training Loss: 0.2171, Validation Loss: 0.2551\n",
      "Epoch: 28/100, Training Loss: 0.2145, Validation Loss: 0.2533\n",
      "Epoch: 29/100, Training Loss: 0.2103, Validation Loss: 0.2505\n",
      "Epoch: 30/100, Training Loss: 0.2067, Validation Loss: 0.2521\n",
      "Epoch: 31/100, Training Loss: 0.2029, Validation Loss: 0.2490\n",
      "Epoch: 32/100, Training Loss: 0.2002, Validation Loss: 0.2479\n",
      "Epoch: 33/100, Training Loss: 0.1963, Validation Loss: 0.2498\n",
      "Epoch: 34/100, Training Loss: 0.1935, Validation Loss: 0.2483\n",
      "Epoch: 35/100, Training Loss: 0.1931, Validation Loss: 0.2455\n",
      "Epoch: 36/100, Training Loss: 0.1898, Validation Loss: 0.2457\n",
      "Epoch: 37/100, Training Loss: 0.1863, Validation Loss: 0.2449\n",
      "Epoch: 38/100, Training Loss: 0.1843, Validation Loss: 0.2430\n",
      "Epoch: 39/100, Training Loss: 0.1797, Validation Loss: 0.2447\n",
      "Epoch: 40/100, Training Loss: 0.1777, Validation Loss: 0.2423\n",
      "Epoch: 41/100, Training Loss: 0.1753, Validation Loss: 0.2433\n",
      "Epoch: 42/100, Training Loss: 0.1709, Validation Loss: 0.2433\n",
      "Epoch: 43/100, Training Loss: 0.1705, Validation Loss: 0.2397\n",
      "Epoch: 44/100, Training Loss: 0.1687, Validation Loss: 0.2477\n",
      "Epoch: 45/100, Training Loss: 0.1679, Validation Loss: 0.2462\n",
      "Epoch: 46/100, Training Loss: 0.1662, Validation Loss: 0.2425\n",
      "Epoch: 47/100, Training Loss: 0.1618, Validation Loss: 0.2413\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for images, labels in train_load:\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_losses.append(train_loss / len(train_load))\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_load:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_losses.append(val_loss / len(val_load))\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}/{epochs}, Training Loss: {train_losses[-1]:.4f}, Validation Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Training time: {end - start:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e39Zf1053VUQ"
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(loader, model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "test_accuracy = evaluate_accuracy(test_load, model)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ujGOI6CL3Wkq"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label='Training Loss', color='blue')\n",
    "plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss', color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VjvwFrH8nuw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
